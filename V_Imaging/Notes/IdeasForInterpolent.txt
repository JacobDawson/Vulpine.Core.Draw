

- I think that Tileablility should be a property of the Image class. For several reasons:

  - There are several methods which depend on tileablity, apart form interpolation. Such as
    applying filters (convolution cernals) and computing the foyier transform.

  - It dosen't NEED to be handled in the interpolent class, which cuts down on the number
    of things the interpolent class needs to track.

  - It really IS a property of the image, as tilablility depends entierly on the image
    in question, and it's apearance.

  - The only downside is that every sub-class of image would need to suport this feature.
    Which may amount to simply including aditional constructors.
	

- Things I want to add to Interpolent:

  - A mask or border property, to determin what should happen when sampeling points that
    lie outside the bounds of the internal image. 

	- Note this is diffrent from tileablilty, as interpolation itself depends upon
	  weather the image is tilable or not.

	- This is better served as part of the Interpolent class, so that we don't have to
	  waist any time interpolating data that lies outside the internal image.

  - Some sort of gamma correction option. This is important, because interpolation ultemently
    involves the blending of colors, and colors blend more smoothly when gama is taken into
	account. Basicly it should adjust the gamma before interpolating, then turn it back after.

	- Alternitivly, we could spesify the color space to use for interpolation. Interpolating
	  in XYZ or LAB has the same bonus as adjusting gamma, but is much more expensive. Its
	  unclear why someone might want to interpolate in HSL or YUV.

  - Premultiplying Alpha: I'm not as shure about this one. Basicly my whole library assumes
    that alpha is premultiplied. However, not all sorces may be premultiplied. Adding this
	to Interpolent allows it to multiply the alphas before interpolating. However this
	may be better built into the Image class, or one of it's sub clases.

  - Output Selection: I had this one in my old notes, but I'm not shure why I wanted it.
    I think the idea was that, if we only wanted one of the channels, we dident need to waist
	time interpolating the other channels. For instance if we only cared about the grayscale
	values we could just interpolate those, and not the full RGB values.

	- This might be more usefull once I get into combining textures, and using texturs for
	  diffrent things, such as bump maps in ray tracing.

	- It feels like it might be a bit overkill, since all colors have 4 values, regardless of
	  what they are ment to represent. Though it could give significant savings if you are
	  interpolating a bunch of textures using Sinc3 or something.

	- Selection from old notes: RGB, RGBA, Alpha, Luma, YUV?


======================================================================================================



- The main thing I want to change for the Interpolation class is to keep it from distorting
  the input image. In the past, it scaled the image to fit inside the unit square, by scaling
  both the X and Y axis. However, this distorts the image by streaching it.

  - Idealy I would like to scale the image so that it fits inside the unit square without
    streaching. This seems like an ideal starting point, since textures are ment to be
	independent of scale.
	
  - However what if I actualy want to streach the image? Like what if I want to resise an
    image by wraping it in a texture, and rendering it out to another image? I don't see
	how this is presently possable without having the image fill the texture space. 


- As an alternit idea, I could change the way that Render works. In order to make the source
  image fit inside the target, we need to be able to compare their aspect ratios. This would
  require textures to pass along their aspect ratio information. 

  - Most textures though are infinite in scope, so assining an aspect ratio to them seems dubious.
    Perhaps a scale factor would be more apropriate? Most textures would have a scale factor of
	1:1, but this could be used to indicate that an image has been distorted.

  - Many, many diffrent classes could potentialy be interpreted as textures, which is why I
    decided to make Texture an interface. To make it easy to implement, I would like to
	keep the interface as simple as possable. And most textures just don't need a scale factor.


- I could set it up so that the user determins if the texture is scaled on the X axis, or the
  Y axis, or both, similar to what is done for Renderer. This would make fitting the source
  image to the target possable, but is still rather complicated, and requires configuing both
  the Interpolent and the Renderer

  - I think it's better to have a signle universal convention for the UV cordinates, that way
    for any method that accepts a texture, you pretty much know what the UV cordinates mean. 

  - I don't like adding superflous features to the Interpolent class.


======================================================================================================

Decisions:

- Consider renaming Interpolent to TextureImage.

- Add Tileing / Mirroring options to the Image class, as this is important for image filters and
  foyer analisis.

- Masking will be part of the Interpolent / TextureImage class.

- The user should determin the scaling of an Interpolent / TestureImage in the same way they do
  for the renderer [ScaleX, ScaleY, Strech]

- The default scaling option for Interpolent / TestureImage should probably be Strech, since this
  is what Interpolent curently dose, it offers the best backwards compatablity.

- Don't worry about alpha values for now. Instead continue on the assumption that ALL alpha values
  are premultiplied. We may need to add a Premultiply option to ImageSytem in the future.

- I might as well add Output Selection to Interpolent / TextureImage, as it dosen't relly hurt
  anything and it's better to add it now rather than latter.

- In retrospect: adding outpout opitions dosen't speed up computation by all that much in the
  default case. Yet adding the ouption would require rewriting all of the interpolation methods
  which I'm not shure I feel compelled to do just now.

- The options for masking / borders should be [None, Transparent, Matte] with the third option
  producing a color determined by a second paramater, Background or Matte

- I still need to think more on gamma correction:


======================================================================================================

Regarding Gamma:

- There are two possabilities to consider: One is making gamma a part of Interpolent / TextureImage and
  simply leaving it at that. The other is making it a part of Image, requiring that all floating-point
  Colors be gamma scaled. The latter is considerably more work, but is is worth it?

- For the most part, adding gamma correction to Interpolent / TextureImage should be suffiecen. Gamma
  bleed usualy only occors during interpolation. So once we can sample an image as a continious texture,
  we no longer need to worry about gamma bleed.

- There may be other casses where having correct gamma values could be benificial. It is unclear how
  gamma correction could affect filters that use convolution cernals. Any time two values are compared,
  for example finding the distance or midpoint between two colors, it's arguably better to have gamma
  corected values.

- This would already change things like Pallets, where the answer to "what is the closest color" would
  be diffrent with gamma corrected values, and could potentialy lead to better results.

- Other collor spaces would change as well. HSL and HSV would then be gamma-corrected HSL and HSV. Curently
  there are sharp peeks in hue for Yellow, Cyan, and Magenta. Would gamma-correction allow for a smoother
  gradient of hues? - No.

- The definition for XYZ space would need to change. Since it requires gamma correct values from the get-go
  it includes a form of gamma correction in the conversion from RGB to XYZ. However if the RGB values are
  already gamma correct, this step becomes redundant and should be removed.

- The whole reason gamma values exist, is because humans precieve luminance on a logrythmic scale. However
  most image information is stored in descreet bits. To get the most value out of those bits, it's more
  economic to store the log of the luminance, than the actual luminance. However, this is not an issue
  with floating point values. Since floating point values have a logrythimic scale built in, (there are
  more floating poitn values near zero than one) we can simply store the luminance values directly. 

- From my exprements with the color wheel I think it's clear that I should not implement gamma.